name: llama.cpp optional build

on:
  workflow_dispatch:
  push:
    paths:
      - 'integrations/llama.cpp/**'
      - '.github/workflows/llamacpp-build.yml'
  pull_request:
    paths:
      - 'integrations/llama.cpp/**'
      - '.github/workflows/llamacpp-build.yml'

env:
  CMAKE_VERSION: '3.24.0'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install cmake
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake ninja-build

      - name: Verify cmake installation
        run: |
          cmake --version
          ninja --version

      - name: Fetch llama.cpp and dependencies
        working-directory: integrations/llama.cpp
        run: |
          bash fetch.sh

      - name: Build llama.cpp with cmake
        working-directory: integrations/llama.cpp
        run: |
          bash build.sh

      - name: Verify build artifacts
        working-directory: integrations/llama.cpp
        run: |
          ls -lh llama.cpp/build/
          echo "Build completed successfully"
